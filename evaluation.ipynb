{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b389c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import linalg\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Cố gắng import metrics từ file local, nếu không có thì dùng fallback implementation dưới\n",
    "try:\n",
    "    from utils import metrics\n",
    "    HAS_METRICS = True\n",
    "except Exception as e:\n",
    "    print(\"Không load được metrics.py (sẽ dùng fallback). Lỗi:\", e)\n",
    "    HAS_METRICS = False\n",
    "\n",
    "# Cấu hình chung\n",
    "FEATURE_POOLING = \"mean\"   # options: \"mean\", \"max\", \"last\"\n",
    "COV_EPS = 1e-6             # regularization cho covariance nếu cần\n",
    "TOP_K_VALUES = [1, 3, 5]\n",
    "OUTPUT_RESULTS_JSON = \"eval_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3240bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/serverai/ltdoanh/Motion_Diffusion/checkpoints/beat/test/opt.txt\n",
      "Loaded mean/std from ./checkpoints/beat/test/meta\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 12.75 MiB is free. Process 3741889 has 58.55 GiB memory in use. Process 3888573 has 18.95 GiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.27 GiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKhông tìm thấy mean/std hoặc lỗi load:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m---> 50\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDDPMTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m trainer\u001b[38;5;241m.\u001b[39mload(pjoin(opt\u001b[38;5;241m.\u001b[39mmodel_dir, opt\u001b[38;5;241m.\u001b[39mwhich_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tar\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     53\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval_mode()\n",
      "File \u001b[0;32m~/ltdoanh/Motion_Diffusion/trainers/ddpm_trainer.py:53\u001b[0m, in \u001b[0;36mDDPMTrainer.__init__\u001b[0;34m(self, args, encoder)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mis_train:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmse_criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ltdoanh/Motion_Diffusion/trainers/ddpm_trainer.py:151\u001b[0m, in \u001b[0;36mDDPMTrainer.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mis_train:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmse_criterion\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:1369\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 928 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:955\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 955\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m/srv/conda/envs/serverai/layout/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1350\u001b[0m             device,\n\u001b[1;32m   1351\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m             non_blocking,\n\u001b[1;32m   1353\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1354\u001b[0m         )\n\u001b[0;32m-> 1355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 12.75 MiB is free. Process 3741889 has 58.55 GiB memory in use. Process 3888573 has 18.95 GiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.27 GiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# Thêm các import bạn đã chỉ ra (chỉnh đường dẫn import nếu cần)\n",
    "# from models import MotionTransformer        # nếu file models.py có trong PYTHONPATH\n",
    "# from utils.get_opt import get_opt\n",
    "# from trainers import DDPMTrainer\n",
    "\n",
    "# Nếu các import trên bị lỗi do path, chỉnh sys.path trước:\n",
    "# import sys\n",
    "# sys.path.append(\"/home/serverai/ltdoanh/Motion_Diffusion/\")  # chỉnh theo repo của bạn\n",
    "\n",
    "# Config: đường dẫn opt, checkpoint sẽ lấy từ opt (giống code bạn gửi)\n",
    "OPT_PATH = \"/home/serverai/ltdoanh/Motion_Diffusion/checkpoints/beat/test/opt.txt\"  # chỉnh nếu khác\n",
    "APPLY_DENORMALIZE = True   # nếu model output được chuẩn hoá và bạn muốn nhân *std + mean\n",
    "\n",
    "# --- Khởi tạo encoder & trainer giống code bạn đưa ---\n",
    "# NOTE: nếu bạn đã có encoder/trainer ở scope khác, bạn có thể skip phần khởi tạo\n",
    "try:\n",
    "    from models import MotionTransformer\n",
    "    from utils.get_opt import get_opt\n",
    "    from trainers import DDPMTrainer\n",
    "except Exception as e:\n",
    "    print(\"Warning: không import được các module model/trainer trực tiếp. Nếu notebook nằm ngoài repo, bổ sung sys.path. Lỗi:\", e)\n",
    "\n",
    "# tạo encoder (cần khớp với config của bạn)\n",
    "encoder = MotionTransformer(\n",
    "    input_feats=264,\n",
    "    num_frames=360,\n",
    "    num_layers=8,\n",
    "    latent_dim=512,\n",
    "    no_clip=False,\n",
    "    no_eff=False\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "opt = get_opt(OPT_PATH, device)\n",
    "opt.do_denoise = True\n",
    "\n",
    "# load mean/std nếu muốn denormalize\n",
    "mean = None\n",
    "std = None\n",
    "try:\n",
    "    mean = np.load(pjoin(opt.meta_dir, 'mean.npy'))\n",
    "    std = np.load(pjoin(opt.meta_dir, 'std.npy'))\n",
    "    print(\"Loaded mean/std from\", opt.meta_dir)\n",
    "except Exception as e:\n",
    "    print(\"Không tìm thấy mean/std hoặc lỗi load:\", e)\n",
    "\n",
    "trainer = DDPMTrainer(opt, encoder)\n",
    "trainer.load(pjoin(opt.model_dir, opt.which_epoch + '.tar'))\n",
    "\n",
    "trainer.eval_mode()\n",
    "trainer.to(opt.device)\n",
    "\n",
    "print(\"Model & trainer đã load. Device:\", opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11219ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 NPYs\n",
      "34 TXT prompts\n",
      "Loaded prompts: 34\n"
     ]
    }
   ],
   "source": [
    "# Folder chứa cả .npy và .txt\n",
    "TEST_FOLDER_NPY = \"/home/serverai/ltdoanh/Motion_Diffusion/datasets/BEAT_testing/npy\"\n",
    "TEST_FOLDER_TXT = \"/home/serverai/ltdoanh/Motion_Diffusion/datasets/BEAT_testing/txt\"\n",
    "\n",
    "# Lấy file npy và txt\n",
    "real_feature_files = sorted(glob.glob(os.path.join(TEST_FOLDER_NPY, \"*.npy\")))\n",
    "prompt_files = sorted(glob.glob(os.path.join(TEST_FOLDER_TXT, \"*.txt\")))\n",
    "\n",
    "# Kiểm tra số lượng\n",
    "print(len(real_feature_files), \"NPYs\")\n",
    "print(len(prompt_files), \"TXT prompts\")\n",
    "\n",
    "# Đọc prompt\n",
    "LIST_OF_TEST_PROMPTS = []\n",
    "for txt_file in prompt_files:\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        LIST_OF_TEST_PROMPTS.append(f.read().strip())\n",
    "\n",
    "print(\"Loaded prompts:\", len(LIST_OF_TEST_PROMPTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdba134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 .npy files, 34 prompts provided.\n"
     ]
    }
   ],
   "source": [
    "# Tìm file thật và kiểm tra số lượng\n",
    "# real_feature_files = sorted(glob.glob(PATH_TO_TEST_NPYS))\n",
    "n_files = len(real_feature_files)\n",
    "n_prompts = len(LIST_OF_TEST_PROMPTS)\n",
    "print(f\"Found {n_files} .npy files, {n_prompts} prompts provided.\")\n",
    "\n",
    "if n_files == 0:\n",
    "    raise FileNotFoundError(\"Không tìm thấy file .npy nào. Kiểm tra PATH_TO_TEST_NPYS.\")\n",
    "if n_files != n_prompts:\n",
    "    print(\"⚠️ Cảnh báo: Số lượng .npy và prompts không khớp.\")\n",
    "    N = min(n_files, n_prompts)\n",
    "    print(f\"Sẽ dùng N = {N} (min of files/prompts). Vui lòng đảm bảo thứ tự tương ứng.\")\n",
    "else:\n",
    "    N = n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6783b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm pooling (T, D) -> (D,)\n",
    "def pool_segment(segment: np.ndarray, pooling: str = \"mean\"):\n",
    "    if segment is None:\n",
    "        return None\n",
    "    if segment.ndim == 1:\n",
    "        return segment\n",
    "    if pooling == \"mean\":\n",
    "        return np.mean(segment, axis=0)\n",
    "    elif pooling == \"max\":\n",
    "        return np.max(segment, axis=0)\n",
    "    elif pooling == \"last\":\n",
    "        return segment[-1]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown pooling: \" + str(pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded08be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and pooling 34 real feature files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 2972.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_features shape: (34, 264)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tải real features (với pooling)\n",
    "real_features_list = []\n",
    "print(f\"Loading and pooling {N} real feature files...\")\n",
    "for i in tqdm(range(N)):\n",
    "    npy_file = real_feature_files[i]\n",
    "    seg = np.load(npy_file)\n",
    "    vec = pool_segment(seg, FEATURE_POOLING)\n",
    "    real_features_list.append(vec)\n",
    "real_features = np.vstack(real_features_list)  # (N, D)\n",
    "print(\"real_features shape:\", real_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 34 features from prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 4292.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_features shape: (34, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Generate features using your trainer (replaces previous generated_features cell) ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pooling function (reuse from notebook)\n",
    "def pool_segment(segment: np.ndarray, pooling: str = \"mean\"):\n",
    "    if segment is None:\n",
    "        return None\n",
    "    if segment.ndim == 1:\n",
    "        return segment\n",
    "    if pooling == \"mean\":\n",
    "        return np.mean(segment, axis=0)\n",
    "    elif pooling == \"max\":\n",
    "        return np.max(segment, axis=0)\n",
    "    elif pooling == \"last\":\n",
    "        return segment[-1]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown pooling: \" + str(pooling))\n",
    "\n",
    "# Params: bạn có thể thay đổi pooling, seq_len (frame length) nếu cần\n",
    "FEATURE_POOLING = \"mean\"    # \"mean\" / \"max\" / \"last\"\n",
    "DEFAULT_NUM_FRAMES = getattr(opt, \"num_frames\", 360)  # nếu opt có num_frames thì dùng\n",
    "RESULTS_SAVE_DIR = pjoin(opt.result_dir if hasattr(opt, \"result_dir\") else \".\", \"\")\n",
    "\n",
    "generated_features_list = []\n",
    "print(f\"Đang sinh {N} mẫu từ model... (pooling={FEATURE_POOLING})\")\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    # lấy prompt tương ứng (LIST_OF_TEST_PROMPTS phải đã được load)\n",
    "    prompt = LIST_OF_TEST_PROMPTS[i]\n",
    "\n",
    "    # trainer.generate thường nhận list of captions và lengths -> chúng ta gọi 1 sample mỗi lần\n",
    "    caption = [prompt]\n",
    "    # length: dùng DEFAULT_NUM_FRAMES hoặc bạn có ở real data\n",
    "    try:\n",
    "        m_lens = torch.LongTensor([int(DEFAULT_NUM_FRAMES)]).to(device)\n",
    "    except Exception:\n",
    "        m_lens = torch.LongTensor([360]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Một số trainer.generate trả về list of tensors; giữ nguyên tương thích\n",
    "        pred_motions = trainer.generate(caption, m_lens, 264)  # 264 là input_feats bạn dùng\n",
    "        # pred_motions expected: list/tuple of tensors (B, T, D) hoặc tensor (B, T, D)\n",
    "        if isinstance(pred_motions, (list, tuple)):\n",
    "            pred = pred_motions[0]\n",
    "        else:\n",
    "            pred = pred_motions\n",
    "\n",
    "        # đưa về CPU numpy\n",
    "        motion = pred.cpu().numpy()  # shape (T, D) or (B, T, D) ? if B dimension present, take first\n",
    "        # if batch dim present\n",
    "        if motion.ndim == 3:\n",
    "            motion = motion[0]  # (T, D)\n",
    "\n",
    "    # optional: denormalize if mean/std loaded and flagged\n",
    "    if APPLY_DENORMALIZE and (mean is not None) and (std is not None):\n",
    "        try:\n",
    "            # mean/std could be shape (D,) or (1, D)\n",
    "            motion = motion * std + mean\n",
    "        except Exception as e:\n",
    "            # fallback: if shapes don't broadcast, try per-dim\n",
    "            if mean.shape[0] == motion.shape[-1]:\n",
    "                motion = motion * mean + std  # (best-effort, but this is unusual)\n",
    "            else:\n",
    "                print(f\"Không thể denormalize do shape mismatch: motion {motion.shape}, mean {None if mean is None else mean.shape}, std {None if std is None else std.shape}. Lỗi: {e}\")\n",
    "\n",
    "    # Save raw motion optionally per-sample\n",
    "    try:\n",
    "        # lưu mỗi motion nếu cần (comment nếu không muốn)\n",
    "        np.save(pjoin(RESULTS_SAVE_DIR, f\"generated_motion_{i:04d}.npy\"), motion)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Pool to vector\n",
    "    vec = pool_segment(motion, FEATURE_POOLING)\n",
    "    generated_features_list.append(vec)\n",
    "\n",
    "generated_features = np.vstack(generated_features_list)\n",
    "print(\"Đã sinh xong generated_features shape:\", generated_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback implementation cho Frechet Distance (nếu metrics.calculate_frechet_distance không có)\n",
    "def _fallback_calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    # regularize\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    dim = mu1.shape[0]\n",
    "    assert mu2.shape[0] == dim\n",
    "    # add eps to diagonal if needed\n",
    "    offset = np.eye(dim) * eps\n",
    "    covmean, _ = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset), disp=False)\n",
    "    # numerical fix: if imaginary due to numerical error, take real part\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.imag(covmean), 0, atol=1e-3):\n",
    "            raise ValueError(\"Imaginary component found in sqrtm result.\")\n",
    "        covmean = np.real(covmean)\n",
    "    diff = mu1 - mu2\n",
    "    fid = diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * np.trace(covmean)\n",
    "    return float(np.real(fid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bee8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing FID...\n",
      "Lỗi khi tính FID: Training and test mean vectors have different lengths\n",
      "Vẫn lỗi khi tính FID: \n"
     ]
    }
   ],
   "source": [
    "# Compute means & covariances, then FID\n",
    "mu_real = np.mean(real_features, axis=0)\n",
    "sigma_real = np.cov(real_features, rowvar=False)\n",
    "mu_gen = np.mean(generated_features, axis=0)\n",
    "sigma_gen = np.cov(generated_features, rowvar=False)\n",
    "\n",
    "print(\"Computing FID...\")\n",
    "try:\n",
    "    if HAS_METRICS and hasattr(metrics, \"calculate_frechet_distance\"):\n",
    "        fid_score = metrics.calculate_frechet_distance(mu_real, sigma_real, mu_gen, sigma_gen)\n",
    "    else:\n",
    "        fid_score = _fallback_calculate_frechet_distance(mu_real, sigma_real, mu_gen, sigma_gen, eps=COV_EPS)\n",
    "    print(f\"FID = {fid_score:.6f}\")\n",
    "except Exception as e:\n",
    "    print(\"Lỗi khi tính FID:\", e)\n",
    "    # last-resort: try with larger eps\n",
    "    try:\n",
    "        fid_score = _fallback_calculate_frechet_distance(mu_real, sigma_real, mu_gen, sigma_gen, eps=1e-3)\n",
    "        print(\"FID (with larger eps) =\", fid_score)\n",
    "    except Exception as e2:\n",
    "        print(\"Vẫn lỗi khi tính FID:\", e2)\n",
    "        fid_score = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946f7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance matrix and Top-K accuracies...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "XA and XB must have the same number of columns (i.e. feature dimension.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing distance matrix and Top-K accuracies...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# dist_matrix shape: (N_generated, N_real)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dist_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(dist_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m correct_matches \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m TOP_K_VALUES}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/spatial/distance.py:3108\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   3106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXB must be a 2-dimensional array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m sB[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 3108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXA and XB must have the same number of columns \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3109\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(i.e. feature dimension.)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3111\u001b[0m mA \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3112\u001b[0m mB \u001b[38;5;241m=\u001b[39m sB[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: XA and XB must have the same number of columns (i.e. feature dimension.)"
     ]
    }
   ],
   "source": [
    "# Tính Top-K retrieval metrics (R-Precision @1 and Top-K)\n",
    "print(\"Computing distance matrix and Top-K accuracies...\")\n",
    "# dist_matrix shape: (N_generated, N_real)\n",
    "dist_matrix = cdist(generated_features, real_features, metric=\"euclidean\")\n",
    "sorted_indices = np.argsort(dist_matrix, axis=1)\n",
    "\n",
    "correct_matches = {k: 0 for k in TOP_K_VALUES}\n",
    "for i in range(N):\n",
    "    ground_truth_index = i\n",
    "    for k in TOP_K_VALUES:\n",
    "        top_k = sorted_indices[i, :k]\n",
    "        if ground_truth_index in top_k:\n",
    "            correct_matches[k] += 1\n",
    "\n",
    "topk_results = {}\n",
    "for k in TOP_K_VALUES:\n",
    "    acc = correct_matches[k] / N\n",
    "    topk_results[f\"top_{k}_acc\"] = float(acc)\n",
    "    print(f\"Top-{k} Accuracy: {acc*100:.2f}% {'(R-Precision @1)' if k==1 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ae7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topk_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Lưu kết quả vào file JSON\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(N),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_pooling\u001b[39m\u001b[38;5;124m\"\u001b[39m: FEATURE_POOLING,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m fid_score \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(fid_score),\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtopk_results\u001b[49m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto-eval run. Ensure real .npy files and prompts are aligned.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUTPUT_RESULTS_JSON, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(results, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topk_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Lưu kết quả vào file JSON\n",
    "results = {\n",
    "    \"N\": int(N),\n",
    "    \"feature_pooling\": FEATURE_POOLING,\n",
    "    \"fid\": None if fid_score is None else float(fid_score),\n",
    "    \"topk\": topk_results,\n",
    "    \"notes\": \"Auto-eval run. Ensure real .npy files and prompts are aligned.\"\n",
    "}\n",
    "with open(OUTPUT_RESULTS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "print(\"Saved results to\", OUTPUT_RESULTS_JSON)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
