{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4393cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymo.parsers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BVHParser\n\u001b[1;32m      3\u001b[0m parser \u001b[38;5;241m=\u001b[39m BVHParser()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#fbs  = 60\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymo.parsers'"
     ]
    }
   ],
   "source": [
    "from pymo.parsers import BVHParser\n",
    "\n",
    "parser = BVHParser()\n",
    "#fbs  = 60\n",
    "parsed_data = parser.parse('/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT/beat_english_v0.2.1/beat_english_v0.2.1/1/1_wayne_0_1_1.bvh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymo.viz_tools import *\n",
    "\n",
    "print_skel(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e44299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "ROOT = os.path.expanduser(\"/home/serverai/ltdoanh/Motion_Diffusion/datasets/pymo\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "from pymo.pymo.preprocessing import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data_pipe = Pipeline([\n",
    "    ('param', MocapParameterizer('position')),\n",
    "    ('rcpn', RootCentricPositionNormalizer()),\n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),\n",
    "    ('const', ConstantsRemover()),\n",
    "    ('np', Numpyfier()),\n",
    "    ('down', DownSampler(2)),\n",
    "    ('stdscale', ListStandardScaler())\n",
    "])\n",
    "\n",
    "piped_data = data_pipe.fit_transform([parsed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd5348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4140, 264)\n"
     ]
    }
   ],
   "source": [
    "print(piped_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e56326",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = np.split(piped_data, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import numpy as np  \n",
    "from textgrid import TextGrid  \n",
    "  \n",
    "def time_to_frame(t, fps=60):  \n",
    "    return int(round(t * fps))  \n",
    "  \n",
    "def extract_sentences_with_text(  \n",
    "    textgrid_path, text_path, motion_data, output_dir, fps=30, pause_threshold=0.5,   \n",
    "    split_parts=2, use_first_part_only=True  \n",
    "):  \n",
    "    basename = os.path.splitext(os.path.basename(textgrid_path))[0]  \n",
    "      \n",
    "    # √Åp d·ª•ng c√°ch t√°ch frames nh∆∞ trong PyMO pipeline  \n",
    "    if motion_data.ndim == 3:  # Shape: (1, frames, features)  \n",
    "        # Split d·ªØ li·ªáu theo axis=1 (features)  \n",
    "        split_data = np.split(motion_data, split_parts, axis=1)  \n",
    "          \n",
    "        if use_first_part_only:  \n",
    "            # L·∫•y ph·∫ßn ƒë·∫ßu ti√™n v√† reshape t·ª´ 3D v·ªÅ 2D  \n",
    "            motion = split_data[0].squeeze(0)  # Shape: (frames, features/2)  \n",
    "        else:  \n",
    "            # Reshape t·∫•t c·∫£ c√°c ph·∫ßn  \n",
    "            reshaped_data = [data.squeeze(0) for data in split_data]  \n",
    "            motion = reshaped_data[0]  # S·ª≠ d·ª•ng ph·∫ßn ƒë·∫ßu ti√™n  \n",
    "    else:  \n",
    "        # N·∫øu ƒë√£ l√† 2D, s·ª≠ d·ª•ng tr·ª±c ti·∫øp  \n",
    "        motion = motion_data[0] if motion_data.ndim == 2 else motion_data  \n",
    "      \n",
    "    max_frames = motion.shape[0]  \n",
    "      \n",
    "    tg = TextGrid.fromFile(textgrid_path)  \n",
    "    tier = tg[0]  \n",
    "  \n",
    "    # with open(text_path, 'r') as f:  \n",
    "    #     full_text = f.read().strip()  \n",
    "  \n",
    "    os.makedirs(output_dir, exist_ok=True)  \n",
    "  \n",
    "    sentence_start = None  \n",
    "    sentence_end = None  \n",
    "    sentence_text = []  \n",
    "    sentence_idx = 0  \n",
    "      \n",
    "    def save_sentence():  \n",
    "        nonlocal sentence_idx, sentence_start, sentence_end, sentence_text  \n",
    "          \n",
    "        if not sentence_text or sentence_start is None or sentence_end is None:  \n",
    "            return  \n",
    "              \n",
    "        start_frame = time_to_frame(sentence_start, fps)  \n",
    "        end_frame = time_to_frame(sentence_end, fps)  \n",
    "          \n",
    "        # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° bounds c·ªßa motion data  \n",
    "        start_frame = max(0, start_frame)  \n",
    "        end_frame = min(max_frames, end_frame)  \n",
    "          \n",
    "        if end_frame <= start_frame:  \n",
    "            print(f\"‚ö†Ô∏è Skipped sentence {sentence_idx}: invalid frame range [{start_frame}, {end_frame}]\")  \n",
    "            return  \n",
    "              \n",
    "        motion_segment = motion[start_frame:end_frame, :]  \n",
    "          \n",
    "        fname_base = f\"{basename}_sentence_{sentence_idx:03d}\"  \n",
    "        np.save(os.path.join(output_dir, fname_base + \".npy\"), motion_segment)  \n",
    "          \n",
    "        with open(os.path.join(output_dir, fname_base + \".txt\"), 'w') as ftxt:  \n",
    "            ftxt.write(\" \".join(sentence_text))  \n",
    "          \n",
    "        print(f\"‚úÖ Saved: {fname_base}.npy & .txt (frames: {start_frame}-{end_frame}, shape: {motion_segment.shape})\")  \n",
    "        sentence_idx += 1  \n",
    "  \n",
    "    # X·ª≠ l√Ω TextGrid intervals  \n",
    "    for interval in tier.intervals:  \n",
    "        word = interval.mark.strip()  \n",
    "        xmin = float(interval.minTime)  \n",
    "        xmax = float(interval.maxTime)  \n",
    "  \n",
    "        if word != \"\":  \n",
    "            if sentence_start is None:  \n",
    "                sentence_start = xmin  \n",
    "            sentence_end = xmax  \n",
    "            sentence_text.append(word)  \n",
    "        else:  \n",
    "            pause_duration = xmax - xmin  \n",
    "            if pause_duration >= pause_threshold and sentence_text:  \n",
    "                save_sentence()  \n",
    "                  \n",
    "                # Reset cho c√¢u ti·∫øp theo  \n",
    "                sentence_start = None  \n",
    "                sentence_end = None  \n",
    "                sentence_text = []  \n",
    "  \n",
    "    # L∆∞u c√¢u cu·ªëi c√πng  \n",
    "    if sentence_text:  \n",
    "        save_sentence()  \n",
    "  \n",
    "    print(f\"üéâ Extracted {sentence_idx} sentences from {basename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_000.npy & .txt (frames: 40-204, shape: (164, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_001.npy & .txt (frames: 221-389, shape: (168, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_002.npy & .txt (frames: 408-520, shape: (112, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_003.npy & .txt (frames: 544-694, shape: (150, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_004.npy & .txt (frames: 718-879, shape: (161, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_005.npy & .txt (frames: 896-1176, shape: (280, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_006.npy & .txt (frames: 1194-1247, shape: (53, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_007.npy & .txt (frames: 1282-1479, shape: (197, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_008.npy & .txt (frames: 1500-1774, shape: (274, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_009.npy & .txt (frames: 1791-1866, shape: (75, 264))\n",
      "‚úÖ Saved: 1_wayne_0_1_1_sentence_010.npy & .txt (frames: 1887-2018, shape: (131, 264))\n",
      "üéâ Extracted 11 sentences from 1_wayne_0_1_1\n"
     ]
    }
   ],
   "source": [
    "extract_sentences_with_text(textgrid_path='/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT/beat_english_v0.2.1/beat_english_v0.2.1/1/1_wayne_0_1_1.TextGrid',\n",
    "                            text_path=\"./text.txt\",\n",
    "                            motion_data = piped_data,\n",
    "                            output_dir = \"./\",\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e4aaeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymo.pymo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, ROOT)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BVHParser\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymo.pymo'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "ROOT = os.path.expanduser(\"/home/serverai/ltdoanh/Motion_Diffusion/datasets/pymo\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "import numpy as np\n",
    "from pymo.pymo.parsers import BVHParser\n",
    "from pymo.pymo.preprocessing import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "data_dir = \"/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy\"\n",
    "base_dir = \"/home/serverai/ltdoanh/Motion_Diffusion/datasets/BEAT/1\"\n",
    "npy_out_dir = os.path.join(data_dir , \"npy\")\n",
    "txt_out_dir = os.path.join(data_dir, \"txt\")\n",
    "# os.makedirs(npy_out_dir, exist_ok=True)\n",
    "# os.makedirs(txt_out_dir, exist_ok=True)\n",
    "\n",
    "parser = BVHParser()\n",
    "\n",
    "data_pipe = Pipeline([\n",
    "    ('param', MocapParameterizer('position')),\n",
    "    ('rcpn', RootCentricPositionNormalizer()),\n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),\n",
    "    ('const', ConstantsRemover()),\n",
    "    ('np', Numpyfier()),\n",
    "    ('down', DownSampler(2)),\n",
    "    ('stdscale', ListStandardScaler())\n",
    "])\n",
    "\n",
    "for fname in os.listdir(base_dir):\n",
    "    if fname.endswith(\".bvh\"):\n",
    "        basename = fname.replace(\".bvh\", \"\")\n",
    "        bvh_path = os.path.join(base_dir, fname)\n",
    "        textgrid_path = os.path.join(base_dir, basename + \".TextGrid\")\n",
    "        text_path = os.path.join(base_dir, basename + \".txt\")\n",
    "        if not os.path.exists(textgrid_path) or not os.path.exists(text_path):\n",
    "            continue  # B·ªè qua n·∫øu thi·∫øu file\n",
    "\n",
    "        # Parse BVH v√† ch·∫°y pipeline\n",
    "        if not os.path.exists(textgrid_path) or not os.path.exists(text_path):\n",
    "            continue  # B·ªè qua n·∫øu thi·∫øu file\n",
    "\n",
    "        try:\n",
    "            parsed_data = parser.parse(bvh_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi parse {bvh_path}: {e}\")\n",
    "            continue\n",
    "        piped_data = data_pipe.fit_transform([parsed_data])\n",
    "\n",
    "        # G·ªçi h√†m t√°ch segment\n",
    "        extract_sentences_with_text(\n",
    "            textgrid_path=textgrid_path,\n",
    "            text_path=text_path,\n",
    "            motion_data=piped_data,\n",
    "            output_dir=npy_out_dir,\n",
    "            split_parts=2,\n",
    "            use_first_part_only=True\n",
    "        )\n",
    "\n",
    "        # Di chuy·ªÉn file .txt sang txt_out_dir\n",
    "        for f in os.listdir(npy_out_dir):\n",
    "            if f.endswith(\".txt\"):\n",
    "                os.rename(os.path.join(npy_out_dir, f), os.path.join(txt_out_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa1c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# V√≠ d·ª•:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT·ªïng s·ªë file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcount_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT·ªïng s·ªë file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, count_files(folder_path))\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mcount_files\u001b[0;34m(folder, ext)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_files\u001b[39m(folder, ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    ƒê·∫øm s·ªë file trong folder. N·∫øu ext ƒë∆∞·ª£c cung c·∫•p (v√≠ d·ª• '.bvh'), ch·ªâ ƒë·∫øm file c√≥ ƒëu√¥i ƒë√≥.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext:\n\u001b[1;32m      9\u001b[0m         files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(ext)]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(folder, ext=None):\n",
    "    \"\"\"\n",
    "    ƒê·∫øm s·ªë file trong folder. N·∫øu ext ƒë∆∞·ª£c cung c·∫•p (v√≠ d·ª• '.bvh'), ch·ªâ ƒë·∫øm file c√≥ ƒëu√¥i ƒë√≥.\n",
    "    \"\"\"\n",
    "    files = os.listdir(folder)\n",
    "    if ext:\n",
    "        files = [f for f in files if f.endswith(ext)]\n",
    "    return len(files)\n",
    "\n",
    "# V√≠ d·ª•:\n",
    "folder_path = \"/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/npy\"\n",
    "print(\"T·ªïng s·ªë file:\", count_files(folder_path))\n",
    "\n",
    "folder_path = \"/home/ltdoanh/ldtan/Motion_Diffusion/datasets/BEAT_numpy/txt\"\n",
    "print(\"T·ªïng s·ªë file:\", count_files(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6654bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split d·ªØ li·ªáu  \n",
    "split_data = np.split(piped_data, 2, axis=1)  \n",
    "  \n",
    "# Reshape t·ª´ng ph·∫ßn t·ª´ 3D v·ªÅ 2D  \n",
    "reshaped_data = [data.squeeze(0) for data in split_data]  # Lo·∫°i b·ªè dimension ƒë·∫ßu ti√™n  \n",
    "  \n",
    "# Ho·∫∑c n·∫øu b·∫°n ch·ªâ mu·ªën l·∫•y ph·∫ßn ƒë·∫ßu ti√™n:  \n",
    "first_part = split_data[0].squeeze(0)  # Shape: (2070, 264)  \n",
    "  \n",
    "# Inverse transform  \n",
    "reconstructed_data = data_pipe.inverse_transform([first_part])  \n",
    "  \n",
    "# Visualize  \n",
    "draw_stickfigure(reconstructed_data[0], frame=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70b89d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ListStandardScaler' object has no attribute 'data_std_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, ROOT)\n\u001b[1;32m      6\u001b[0m pipe_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/serverai/ltdoanh/Motion_Diffusion/checkpoints/motion.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m reconstructed_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpipe_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_stickfigure\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sau ƒë√≥ c√≥ th·ªÉ visualize  \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1138\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1136\u001b[0m reverse_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()))\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m reverse_iter:\n\u001b[0;32m-> 1138\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/ltdoanh/Motion_Diffusion/datasets/pymo/pymo/preprocessing.py:698\u001b[0m, in \u001b[0;36mListStandardScaler.inverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    696\u001b[0m         unnormalized_track\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m (track\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_std_) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_mean_\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m         unnormalized_track \u001b[38;5;241m=\u001b[39m (track \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_std_\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_mean_\n\u001b[1;32m    700\u001b[0m     Q\u001b[38;5;241m.\u001b[39mappend(unnormalized_track)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_DataFrame:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ListStandardScaler' object has no attribute 'data_std_'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "ROOT = os.path.expanduser(\"/home/serverai/ltdoanh/Motion_Diffusion/datasets/pymo\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "pipe_data = np.load(\"/home/serverai/ltdoanh/Motion_Diffusion/checkpoints/motion.npy\")\n",
    "reconstructed_data = data_pipe.inverse_transform([pipe_data])  \n",
    "from pymo.pymo.viz_tools import draw_stickfigure\n",
    "# Sau ƒë√≥ c√≥ th·ªÉ visualize  \n",
    "draw_stickfigure(reconstructed_data[0], frame=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MocapParameterizer('position')\n",
    "\n",
    "positions = mp.fit_transform([parsed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c6a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymo.data.MocapData at 0x748dec6f0700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5eb45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymo.viz_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_stickfigure\n\u001b[1;32m      2\u001b[0m draw_stickfigure(positions[\u001b[38;5;241m0\u001b[39m], frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m130\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymo.viz_tools'"
     ]
    }
   ],
   "source": [
    "from pymo.viz_tools import draw_stickfigure\n",
    "draw_stickfigure(positions[0], frame=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf045f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymo.preprocessing import *  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "  \n",
    "# T·∫°o pipeline v·ªõi Numpyfier ·ªü cu·ªëi  \n",
    "data_pipe = Pipeline([  \n",
    "    ('param', MocapParameterizer('position')),  \n",
    "    ('rcpn', RootCentricPositionNormalizer()),  \n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),  \n",
    "    ('const', ConstantsRemover()),  \n",
    "    ('np', Numpyfier()),  # Chuy·ªÉn ƒë·ªïi sang numpy array  \n",
    "    ('down', DownSampler(2)),  \n",
    "    ('stdscale', ListStandardScaler())  \n",
    "])  \n",
    "  \n",
    "# √Åp d·ª•ng pipeline  \n",
    "piped_data = data_pipe.fit_transform([parsed_data])  \n",
    "  \n",
    "# Xem shape  \n",
    "print(piped_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6735876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: 000_sentence.npy (81‚Äì407)\n",
      "‚úÖ Saved: 001_sentence.npy (442‚Äì779)\n",
      "‚úÖ Saved: 002_sentence.npy (815‚Äì1041)\n",
      "‚úÖ Saved: 003_sentence.npy (1089‚Äì1387)\n",
      "‚úÖ Saved: 004_sentence.npy (1436‚Äì1759)\n",
      "‚úÖ Saved: 005_sentence.npy (1792‚Äì2351)\n",
      "‚úÖ Saved: 006_sentence.npy (2389‚Äì2495)\n",
      "‚úÖ Saved: 007_sentence.npy (2564‚Äì2959)\n",
      "‚úÖ Saved: 008_sentence.npy (3000‚Äì3547)\n",
      "‚úÖ Saved: 009_sentence.npy (3582‚Äì3732)\n",
      "‚úÖ Saved: 010_sentence.npy (3775‚Äì4036)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from textgrid import TextGrid\n",
    "\n",
    "def time_to_frame(t, fps=60):\n",
    "    return int(round(t * fps))\n",
    "\n",
    "def extract_sentences_with_text(\n",
    "    textgrid_path, text_path, motion_data, output_dir, fps=60, pause_threshold=0.5\n",
    "):\n",
    "    basename = os.path.splitext(os.path.basename(textgrid_path))[0]  # v√≠ d·ª•: 1_wayne_0_1_1\n",
    "    motion = motion_data[0]  # shape: (num_frames, 264)\n",
    "\n",
    "    tg = TextGrid.fromFile(textgrid_path)\n",
    "    tier = tg[0]  # ch·ªâ l·∫•y item[1]\n",
    "\n",
    "    with open(text_path, 'r') as f:\n",
    "        full_text = f.read().strip()\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    sentence_start = None\n",
    "    sentence_end = None\n",
    "    sentence_text = []\n",
    "    sentence_idx = 0\n",
    "\n",
    "    for interval in tier.intervals:\n",
    "        word = interval.mark.strip()\n",
    "        xmin = float(interval.minTime)\n",
    "        xmax = float(interval.maxTime)\n",
    "\n",
    "        if word != \"\":\n",
    "            if sentence_start is None:\n",
    "                sentence_start = xmin\n",
    "            sentence_end = xmax\n",
    "            sentence_text.append(word)\n",
    "        else:\n",
    "            pause = xmax - xmin\n",
    "            if pause >= pause_threshold and sentence_text:\n",
    "                # Save motion\n",
    "                start_frame = time_to_frame(sentence_start, fps)\n",
    "                end_frame = time_to_frame(sentence_end, fps)\n",
    "                motion_segment = motion[start_frame:end_frame, :]\n",
    "\n",
    "                fname_base = f\"{basename}_sentence_{sentence_idx:03d}\"\n",
    "                np.save(os.path.join(output_dir, fname_base + \".npy\"), motion_segment)\n",
    "\n",
    "                # Save sentence text\n",
    "                with open(os.path.join(output_dir, fname_base + \".txt\"), 'w') as ftxt:\n",
    "                    ftxt.write(\" \".join(sentence_text))\n",
    "\n",
    "                print(f\"‚úÖ Saved: {fname_base}.npy & .txt\")\n",
    "\n",
    "                sentence_idx += 1\n",
    "                sentence_start = None\n",
    "                sentence_end = None\n",
    "                sentence_text = []\n",
    "\n",
    "    # Save c√¢u cu·ªëi c√πng n·∫øu c√≤n\n",
    "    if sentence_text:\n",
    "        start_frame = time_to_frame(sentence_start, fps)\n",
    "        end_frame = time_to_frame(sentence_end, fps)\n",
    "        motion_segment = motion[start_frame:end_frame, :]\n",
    "\n",
    "        fname_base = f\"{basename}_sentence_{sentence_idx:03d}\"\n",
    "        np.save(os.path.join(output_dir, fname_base + \".npy\"), motion_segment)\n",
    "        with open(os.path.join(output_dir, fname_base + \".txt\"), 'w') as ftxt:\n",
    "            ftxt.write(\" \".join(sentence_text))\n",
    "        print(f\"‚úÖ Saved: {fname_base}.npy & .txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ t·∫°o /home/ltdoanh/ldtan/Motion_Diffusion/datasets/beat2motion_dataset/train.txt v·ªõi 955 clip id.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Th∆∞ m·ª•c ch·ª©a c√°c segment (npy ho·∫∑c txt)\n",
    "segment_dir = \"/home/ltdoanh/ldtan/Motion_Diffusion/datasets/beat2motion_dataset/npy_segments\"  # s·ª≠a l·∫°i cho ƒë√∫ng ƒë∆∞·ªùng d·∫´n c·ªßa b·∫°n\n",
    "output_txt = \"/home/ltdoanh/ldtan/Motion_Diffusion/datasets/beat2motion_dataset/train.txt\"      # n∆°i l∆∞u file train.txt\n",
    "\n",
    "clip_ids = []\n",
    "for fname in os.listdir(segment_dir):\n",
    "    if fname.endswith(\".npy\"):  # ho·∫∑c \".txt\" n·∫øu mu·ªën l·∫•y theo file text\n",
    "        clip_id = os.path.splitext(fname)[0]\n",
    "        clip_ids.append(clip_id)\n",
    "\n",
    "clip_ids = sorted(set(clip_ids))  # lo·∫°i tr√πng v√† s·∫Øp x·∫øp\n",
    "\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for cid in clip_ids:\n",
    "        f.write(cid + \"\\n\")\n",
    "\n",
    "print(f\"ƒê√£ t·∫°o {output_txt} v·ªõi {len(clip_ids)} clip id.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
